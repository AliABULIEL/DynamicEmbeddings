# Evaluation Configuration for Temporal LoRA

# Retrieval scenarios
scenarios:
  # Within-period: Query and corpus from same bucket
  within:
    enabled: true
    buckets: ["pre_2019", "2019_2024"]
  # Cross-period: Query from one bucket, corpus from another
  cross:
    enabled: true
    pairs:
      - query: "pre_2019"
        corpus: "2019_2024"
      - query: "2019_2024"
        corpus: "pre_2019"
  # All: Query from any bucket, retrieve from all buckets
  all:
    enabled: true

# Retrieval modes
retrieval:
  # Mode: "time-select" (single bucket) or "multi-index" (fusion)
  mode: "multi-index"
  # Multi-index merge strategies: "softmax", "max", "mean", "rrf"
  merge_strategy: "softmax"
  # Top-K for retrieval
  top_k: 100

# Metrics to compute
metrics:
  # NDCG at K
  ndcg_at_k: [10]
  # Recall at K
  recall_at_k: [10, 100]
  # Mean Reciprocal Rank
  mrr: true
  # Precision at K (optional)
  precision_at_k: []

# Statistical tests
statistics:
  # Bootstrap confidence intervals
  bootstrap:
    enabled: true
    n_samples: 1000
    confidence_level: 0.95
    seed: 42
  # Paired permutation test (LoRA vs baseline)
  permutation_test:
    enabled: true
    n_permutations: 10000
    alpha: 0.05
    seed: 42

# Baseline comparison
baseline:
  # Compare against frozen encoder (no LoRA)
  enabled: true
  # Baseline model (same as base_model in model.yaml)
  model_name: "sentence-transformers/all-MiniLM-L6-v2"

# Output paths
output:
  results_dir: "deliverables/results"
  tables_dir: "deliverables/tables"
  # Save detailed per-query results
  save_per_query: false
