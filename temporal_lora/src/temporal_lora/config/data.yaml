# Data Configuration for Temporal LoRA

# Dataset source
dataset:
  # Hugging Face dataset identifier (placeholder - will be updated with actual dataset)
  hf_name: "ccdv/arxiv-classification"
  # Fields to extract
  fields: ["paper_id", "title", "abstract", "year"]

# Time bucketing strategy
buckets:
  # MVP: 2 buckets (≤2018, 2019-2024)
  # Can configure to 3 buckets by adding more definitions
  definitions:
    - name: "≤2018"
      end: 2018    # Inclusive upper bound
    - name: "2019-2024"
      end: 2024    # Inclusive upper bound

# Sampling strategy
sampling:
  # Maximum papers per bucket (for balanced training and fast iteration)
  max_per_bucket: 6000
  # Random seed for reproducibility
  seed: 42

# Preprocessing
preprocessing:
  # Minimum abstract length (characters)
  min_abstract_length: 100
  # Drop papers with missing fields
  drop_missing: true

# Train/val/test splits (per bucket)
splits:
  train: 0.7
  val: 0.1
  test: 0.2
  # Seed for split reproducibility
  seed: 42

# Output paths (relative to project root)
output:
  processed_dir: "data/processed"
  raw_dir: "data/raw"
  csv_fallback: "data/arxiv_cs_ml.csv"
