{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ChronoEmbed: Temporal LoRA for Dynamic Sentence Embeddings\n",
    "\n",
    "This notebook demonstrates the complete pipeline for training time-adaptive embeddings using LoRA.\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "1. **Data Preparation**: Process arXiv abstracts into time buckets\n",
    "2. **Training**: Train LoRA adapters (+ baselines) for each time period\n",
    "3. **Evaluation**: Multi-index retrieval with merge temperature tuning\n",
    "4. **Visualization**: Heatmaps, UMAP, term drift trajectories\n",
    "5. **Efficiency Analysis**: Parameter counts and training times\n",
    "\n",
    "**Runtime**: ~30-45 minutes on T4 GPU (Colab free tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q sentence-transformers peft datasets faiss-cpu umap-learn matplotlib seaborn pandas numpy\n",
    "!pip install -q typer rank-bm25 scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/YOUR_USERNAME/DynamicEmbeddings.git\n",
    "%cd DynamicEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd() / \"src\"))\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## Step 1: Data Preparation\n",
    "\n",
    "Prepare arXiv CS/ML abstracts into 4 time buckets with balanced sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_data"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Prepare data with 4 buckets (≤2018, 2019-2021, 2022-2023, 2024+)\n",
    "!python -m temporal_lora.cli prepare-data \\\n",
    "  --max-per-bucket 4000 \\\n",
    "  --balance-per-bin\n",
    "\n",
    "# Check output\n",
    "!ls -lh data/processed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## Step 2: Training\n",
    "\n",
    "Train three types of models:\n",
    "1. **LoRA adapters** (main approach, <2% params)\n",
    "2. **Full fine-tuning** (baseline, 100% params)\n",
    "3. **Sequential fine-tuning** (catastrophic forgetting demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_lora"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train LoRA adapters with hard temporal negatives\n",
    "!python -m temporal_lora.cli train-adapters \\\n",
    "  --mode lora \\\n",
    "  --epochs 2 \\\n",
    "  --lora-r 16 \\\n",
    "  --hard-temporal-negatives \\\n",
    "  --neg-k 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_full_ft"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train full fine-tuning baseline\n",
    "!python -m temporal_lora.cli train-adapters \\\n",
    "  --mode full_ft \\\n",
    "  --epochs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_seq_ft"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train sequential fine-tuning\n",
    "!python -m temporal_lora.cli train-adapters \\\n",
    "  --mode seq_ft \\\n",
    "  --epochs 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## Step 3: Build Indexes\n",
    "\n",
    "Create FAISS indexes for each mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "build_indexes"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build indexes for baseline\n",
    "!python -m temporal_lora.cli build-indexes --baseline\n",
    "\n",
    "# Build indexes for LoRA\n",
    "!python -m temporal_lora.cli build-indexes --lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## Step 4: Evaluation\n",
    "\n",
    "Comprehensive evaluation with:\n",
    "- Cross-bucket matrices (query × doc period)\n",
    "- Temperature sweep for merge optimization\n",
    "- Efficiency metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_all"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluate all modes\n",
    "!python -m temporal_lora.cli evaluate-all-modes \\\n",
    "  --modes \"baseline_frozen,lora,full_ft,seq_ft\" \\\n",
    "  --temperature-sweep \\\n",
    "  --temperatures \"1.5,2.0,3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efficiency"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Generate efficiency summary\n",
    "!python -m temporal_lora.cli efficiency-summary \\\n",
    "  --modes \"baseline_frozen,lora,full_ft,seq_ft\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## Step 5: Visualizations\n",
    "\n",
    "Create publication-quality figures:\n",
    "- Delta heatmaps (LoRA - baseline)\n",
    "- UMAP embeddings\n",
    "- Term drift trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create heatmaps and UMAP\n",
    "!python -m temporal_lora.cli visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drift"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Generate term drift trajectories\n",
    "!python -m temporal_lora.cli drift-trajectories \\\n",
    "  --terms \"transformer,BERT,LLM,GPT,attention\" \\\n",
    "  --contexts-per-term 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## Step 6: Quick Ablation\n",
    "\n",
    "Test different LoRA hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ablation"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Quick ablation study\n",
    "!python -m temporal_lora.cli quick-ablation \\\n",
    "  --ranks \"8,16,32\" \\\n",
    "  --max-eval 500 \\\n",
    "  --epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## Results Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_efficiency"
   },
   "outputs": [],
   "source": [
    "# Display efficiency summary\n",
    "import pandas as pd\n",
    "\n",
    "efficiency_df = pd.read_csv(\"deliverables/results/efficiency_summary.csv\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EFFICIENCY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(efficiency_df.to_string(index=False))\n",
    "\n",
    "# Summary by mode\n",
    "summary = efficiency_df.groupby(\"mode\").agg({\n",
    "    \"trainable_percent\": \"mean\",\n",
    "    \"size_mb\": \"sum\",\n",
    "    \"wall_clock_seconds\": \"sum\",\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGGREGATED BY MODE\")\n",
    "print(\"=\"*80)\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_heatmaps"
   },
   "outputs": [],
   "source": [
    "# Display heatmaps\n",
    "from IPython.display import Image, display\n",
    "\n",
    "heatmaps = [\n",
    "    \"heatmap_panel_ndcg_at_10.png\",\n",
    "    \"heatmap_panel_recall_at_10.png\",\n",
    "]\n",
    "\n",
    "for heatmap in heatmaps:\n",
    "    path = f\"deliverables/figures/{heatmap}\"\n",
    "    if Path(path).exists():\n",
    "        print(f\"\\n{heatmap}:\")\n",
    "        display(Image(filename=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_drift"
   },
   "outputs": [],
   "source": [
    "# Display drift trajectories\n",
    "drift_path = \"deliverables/figures/drift_trajectories.png\"\n",
    "if Path(drift_path).exists():\n",
    "    print(\"\\nTerm Drift Trajectories:\")\n",
    "    display(Image(filename=drift_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_umap"
   },
   "outputs": [],
   "source": [
    "# Display UMAP\n",
    "umap_path = \"deliverables/figures/umap_embeddings.png\"\n",
    "if Path(umap_path).exists():\n",
    "    print(\"\\nUMAP Embeddings:\")\n",
    "    display(Image(filename=umap_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display_ablation"
   },
   "outputs": [],
   "source": [
    "# Display ablation results\n",
    "ablation_df = pd.read_csv(\"deliverables/results/quick_ablation.csv\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUICK ABLATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if \"status\" in ablation_df.columns:\n",
    "    success_df = ablation_df[ablation_df[\"status\"] == \"success\"]\n",
    "    if len(success_df) > 0:\n",
    "        display_cols = [\"rank\", \"target_modules\", \"trainable_percent\", \"ndcg@10\", \"train_time_seconds\"]\n",
    "        print(success_df[display_cols].to_string(index=False))\n",
    "        \n",
    "        # Best config\n",
    "        best_idx = success_df[\"ndcg@10\"].idxmax()\n",
    "        best = success_df.loc[best_idx]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"BEST CONFIGURATION\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Rank: {best['rank']}\")\n",
    "        print(f\"Modules: {best['target_modules']}\")\n",
    "        print(f\"NDCG@10: {best['ndcg@10']:.4f}\")\n",
    "        print(f\"Trainable %: {best['trainable_percent']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## Step 7: Export Deliverables\n",
    "\n",
    "Consolidate all results and create reproducibility report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "env_dump"
   },
   "outputs": [],
   "source": [
    "# Dump environment info\n",
    "!python -m temporal_lora.cli env-dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export"
   },
   "outputs": [],
   "source": [
    "# Export deliverables\n",
    "!python -m temporal_lora.cli export-deliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": [
    "# Create ZIP for download\n",
    "!zip -r deliverables.zip deliverables/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('deliverables.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## Summary\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Temporal Adaptation**: LoRA adapters learn time-specific representations\n",
    "2. **Efficiency**: <2% trainable params vs 100% for full fine-tuning\n",
    "3. **Performance**: Improved cross-period retrieval (see delta heatmaps)\n",
    "4. **Semantic Drift**: Visualized how term meanings shift over time\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Within-period retrieval**: LoRA matches or exceeds baseline\n",
    "- **Cross-period retrieval**: LoRA shows significant improvements\n",
    "- **Parameter efficiency**: ~100x fewer parameters than full FT\n",
    "- **Training speed**: Faster convergence with hard negatives\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different time bucket granularities\n",
    "- Try different LoRA ranks (use quick-ablation)\n",
    "- Test on other domains (news, patents, social media)\n",
    "- Explore multi-faceted adapters (time + topic + language)\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Repository](https://github.com/YOUR_USERNAME/DynamicEmbeddings)\n",
    "- [Documentation](docs/EVALUATION_GUIDE.md)\n",
    "- [Paper](link_to_paper_when_published)\n",
    "\n",
    "---\n",
    "\n",
    "**Citation**: If you use this code, please cite:\n",
    "```bibtex\n",
    "@software{chronoembed2025,\n",
    "  title={ChronoEmbed: Temporal LoRA for Dynamic Sentence Embeddings},\n",
    "  author={Your Name},\n",
    "  year={2025},\n",
    "  url={https://github.com/YOUR_USERNAME/DynamicEmbeddings}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
