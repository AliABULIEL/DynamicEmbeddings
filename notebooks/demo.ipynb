{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal LoRA for Dynamic Sentence Embeddings - Demo\n",
    "\n",
    "This notebook demonstrates the complete pipeline on a small dataset suitable for Google Colab (T4 GPU).\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1. Environment setup\n",
    "2. Data preparation (6000 samples per time bucket)\n",
    "3. Train LoRA adapters (2 epochs, rank=16)\n",
    "4. Build indexes and evaluate\n",
    "5. Visualize results\n",
    "\n",
    "**Estimated Runtime:** ~15-20 minutes on T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if running on Colab)\n",
    "# !pip install -q torch transformers sentence-transformers peft datasets faiss-cpu pandas numpy matplotlib seaborn umap-learn typer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (uncomment if running on Colab)\n",
    "# !git clone https://github.com/yourusername/DynamicEmbeddings.git\n",
    "# %cd DynamicEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path.cwd()\n",
    "if str(project_root / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture environment for reproducibility\n",
    "!python -m temporal_lora.cli env-dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data\n",
    "\n",
    "Download and preprocess arXiv CS/ML abstracts into time buckets (≤2018, 2019-2024).\n",
    "Using 6000 samples per bucket for quick demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m temporal_lora.cli prepare-data --max-per-bucket 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train LoRA Adapters\n",
    "\n",
    "Train time-bucket LoRA adapters with:\n",
    "- Rank: 16\n",
    "- Epochs: 2\n",
    "- Cross-period negatives: enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m temporal_lora.cli train-adapters --epochs 2 --lora-r 16 --cross-period-negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build Indexes & Evaluate\n",
    "\n",
    "Build FAISS indexes and evaluate both baseline and LoRA systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build baseline indexes\n",
    "!python -m temporal_lora.cli build-indexes --baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LoRA indexes\n",
    "!python -m temporal_lora.cli build-indexes --lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline\n",
    "!python -m temporal_lora.cli evaluate --baseline --mode multi-index --merge softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LoRA\n",
    "!python -m temporal_lora.cli evaluate --lora --mode multi-index --merge softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate heatmaps and UMAP\n",
    "!python -m temporal_lora.cli visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Preview\n",
    "\n",
    "Let's load and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Load results\n",
    "baseline_df = pd.read_csv(\"deliverables/results/baseline_results.csv\", index_col=0)\n",
    "lora_df = pd.read_csv(\"deliverables/results/lora_results.csv\", index_col=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "display(baseline_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LORA RESULTS\")\n",
    "print(\"=\"*60)\n",
    "display(lora_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute improvements\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVEMENTS (Δ = LoRA - Baseline)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "delta_df = lora_df - baseline_df\n",
    "display(delta_df)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nMean Improvements:\")\n",
    "for col in delta_df.columns:\n",
    "    mean_delta = delta_df[col].mean()\n",
    "    print(f\"  {col.upper()}: {mean_delta:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Comparison Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display NDCG@10 comparison heatmap\n",
    "heatmap_path = \"deliverables/figures/comparison_heatmaps_ndcg@10.png\"\n",
    "if Path(heatmap_path).exists():\n",
    "    display(Image(filename=heatmap_path))\n",
    "else:\n",
    "    print(f\"Heatmap not found: {heatmap_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display UMAP projection\n",
    "umap_path = \"deliverables/figures/umap_embeddings.png\"\n",
    "if Path(umap_path).exists():\n",
    "    display(Image(filename=umap_path))\n",
    "else:\n",
    "    print(f\"UMAP not found: {umap_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Deliverables\n",
    "\n",
    "Consolidate all results into a single deliverables package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m temporal_lora.cli export-deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Demo Complete!**\n",
    "\n",
    "The pipeline has successfully:\n",
    "1. Prepared time-bucketed data\n",
    "2. Trained LoRA adapters for each time period\n",
    "3. Built FAISS indexes for retrieval\n",
    "4. Evaluated performance with multiple metrics\n",
    "5. Generated visualizations\n",
    "6. Exported deliverables with reproducibility info\n",
    "\n",
    "**Key Findings:**\n",
    "- LoRA adapters enable **time-aware embeddings** without retraining the base model\n",
    "- Performance improvements are visible in the **Δ (improvement) heatmap**\n",
    "- Cross-period queries benefit from multi-index retrieval with adaptive merging\n",
    "\n",
    "**Next Steps:**\n",
    "- Run ablations to optimize hyperparameters\n",
    "- Analyze term drift trajectories\n",
    "- Scale to larger datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
